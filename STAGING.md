# üß™ Staging Environment Guide

## üìã Overview

L'environnement staging est une r√©plique de production utilis√©e pour tester les modifications avant d√©ploiement.

## üîß Configuration

### Services

- **Database** : Port 5433 (vs 5432 prod)
- **API** : Port 8001 (vs 8000 prod)
- **Web** : Port 8081 (vs 8080 prod)
- **Scraper** : D√©sactiv√© automatiquement (vs cron hebdo prod)

### Images Docker

- **Web** : `latest-staging` (auto-build sur push main)
- **API** : `latest-staging` (auto-build sur push main)
- **Scraper** : `latest-prod` (m√™me image que prod, cron d√©sactiv√©)

## üöÄ D√©ploiement

Le staging se d√©ploie **automatiquement** sur push `main` via GitHub Actions :
1. Build de l'image Docker (web ou api)
2. Push vers GHCR
3. SSH vers le serveur
4. Pull de la nouvelle image
5. Red√©marrage du container

## üóÑÔ∏è Base de donn√©es

La base de donn√©es staging est **compl√®tement isol√©e** de la prod :
- Volume s√©par√© : `mypacer_infra_db_staging_data`
- Pas de r√©initialisation lors des d√©ploiements
- Peut √™tre r√©initialis√©e manuellement si besoin

### R√©initialiser la DB staging

```bash
docker-compose -f docker-compose.staging.yml down
docker volume rm mypacer_infra_db_staging_data
docker-compose -f docker-compose.staging.yml up -d
```

## üï∑Ô∏è Scraper - Lancement manuel

Le scraper staging **ne s'ex√©cute PAS automatiquement** pour √©viter de spammer le site FFA.

### Lancer un scraping complet

```bash
# Depuis le serveur
cd /home/cyril/src/mypacer/mypacer_infra

# Lancer le scraping
docker-compose -f docker-compose.staging.yml exec scraper-staging \
  python -m mypacer_scraper.main

# Voir les logs
docker-compose -f docker-compose.staging.yml logs -f scraper-staging
```

### Lancer uniquement une partie

```bash
# Scraper uniquement les clubs
docker-compose -f docker-compose.staging.yml exec scraper-staging \
  python -m mypacer_scraper.scraper.clubs_scraper

# Scraper uniquement les athl√®tes
docker-compose -f docker-compose.staging.yml exec scraper-staging \
  python -m mypacer_scraper.scraper.athletes_scraper
```

### V√©rifier l'√©tat de la DB apr√®s scraping

```bash
docker-compose -f docker-compose.staging.yml exec db-staging \
  psql -U mypacer_user -d mypacer_staging -c "SELECT * FROM v_athletes_stats;"

docker-compose -f docker-compose.staging.yml exec db-staging \
  psql -U mypacer_user -d mypacer_staging -c "SELECT * FROM v_clubs_stats;"
```

## üîç V√©rification

### Healthchecks

```bash
# Web
curl https://stage.mypacer.fr

# API
curl https://stage.mypacer.fr/api/health
curl https://stage.mypacer.fr/api/database_status

# API docs (Swagger)
open https://stage.mypacer.fr/api/docs
```

### Logs

```bash
cd /home/cyril/src/mypacer/mypacer_infra

# Tous les services
docker-compose -f docker-compose.staging.yml logs -f

# Service sp√©cifique
docker-compose -f docker-compose.staging.yml logs -f web-staging
docker-compose -f docker-compose.staging.yml logs -f api-staging
docker-compose -f docker-compose.staging.yml logs -f scraper-staging
```

### √âtat des containers

```bash
docker-compose -f docker-compose.staging.yml ps
```

## üîÑ Workflow complet

### Tester une modification

1. **D√©velopper** en local avec Docker dev ou directement
2. **Commiter et pusher** sur branche feature
3. **Cr√©er une PR** vers main
4. **Review et merge** la PR
5. **D√©ploiement auto** sur staging (2-3 min)
6. **Tester** sur https://stage.mypacer.fr
7. **Si OK**, cr√©er un tag pour d√©ployer en prod

### D√©ployer en production

```bash
# Cr√©er un tag
git tag -a v0.2.0 -m "Release v0.2.0 - Description"
git push origin v0.2.0

# Le workflow auto va :
# 1. Builder l'image vX.Y.Z-prod
# 2. Cr√©er une release GitHub
# 3. (Futur) D√©ployer en prod automatiquement
```

## ‚ö†Ô∏è Notes importantes

- **Donn√©es staging** : Ne sont PAS synchronis√©es avec prod
- **Scraper staging** : √Ä lancer manuellement (pas de spam FFA)
- **Secrets** : Stock√©s dans GitHub Environments (staging/production)
- **Rollback** : Changer `*_IMAGE_TAG` dans `.env.staging` et `docker-compose up -d`
